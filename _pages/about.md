---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a Ph.D. student at The Hong Kong University of Science and Technology, Guangzhou (HKUSTGZ), supervised by Prof. Li Liu. My research interests include medical image analysis, drug design, and Multi-modal Cued Speech Recognition and Gesture Generation. My research mainly focuses on Multi-modal learning, active learning and semi-supervised learning.

# üî• News
- *2024.03*: One paper accepted by IJCAI 2024
- *2023.12*: One paper accepted by ICASSP 2024
- *2023.06*: Started Ph.D. journey at HKUSTGZ

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2024</div><img src='images/paper1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Bridge to Non-Barrier Communication: Gloss-Prompted Fine-grained Cued Speech Gesture Generation with Diffusion Model](https://arxiv.org/)

**Wentao Lei**, Li Liu, Jun Wang

[**Project**](https://github.com/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Proposed a novel diffusion-based model for cued speech gesture generation
</div>
</div>

## Selected Publications
- [Teaching Others Teaches Yourself: Semi-supervised Ensembled Pseudo-labeling Framework](https://github.com), **Wentao Lei**, Li Liu, **ICASSP 2025**

- [Spatio-Temporal Structure Consistency for Semi-Supervised Medical Image Classification](https://github.com), **Wentao Lei**, Lei Liu, Li Liu, **ICASSP 2023**

- [Semi-Supervised Active Learning for COVID-19 Lung Ultrasound Multi-symptom Classification](https://github.com), Lei Liu\*, **Wentao Lei**\*, Yongfang Luo, Cheng Feng, Xiang Wan, Li Liu, **ICTAI 2020** (*Equal Contribution)

# üìñ Educations
- *2023.06 - present*, Ph.D. in Artificial Intelligence, The Hong Kong University of Science and Technology, Guangzhou
- *2020.09 - 2022.06*, MPhil-Ph.D. Program in Computer and Information Engineering, The Chinese University of Hong Kong, Shenzhen
- *2015.09 - 2019.06*, B.S. in Software Engineering, Wuhan University

# üíª Experience
- *2023 - 2024*, Algorithm Research Intern, Speech Group, Tencent AI Lab, Shenzhen
- *2019 - 2023*, Research Assistant, Shenzhen Research Institute of Big Data (SRIBD)
- *2016 - 2019*, Frontend and Backend Engineer, Advanced Lab of Network Safety, Wuhan University

# üéñ Selected Projects
- **Multi-modal Chinese Cued Speech Recognition and Generation** (2022-2023)
  - Built corpus containing more than 4000 sentences
  - Designed interactive demos with Vue and Flask framework
  - Implemented multi-modal Cued Speech generation algorithms with Diffusion model methods

- **Automatic Liver Fibrosis Diagnosis** (2021)
  - Designed a cost-sensitive algorithm to improve model performance
  - Conducted experiments to validate algorithm effectiveness

- **Covid-19 Lung Ultrasound Classification** (2020)
  - Built datasets containing more than 6000 ultrasound images
  - Designed semi-supervised active learning algorithms
  - Conducted experiments and participated in paper writing

# üí° Skills
- **Programming**: Python, Java, Matlab, Latex (Experienced); Javascript, C++, Bash, Slurm (Familiar)
- **Frameworks**: Jupyter, Matplotlib, Numpy, Pandas, Scikit-learn, Gym, PyTorch, Tensorflow
- **Languages**: Chinese (Native), English (IELTS: 6.5, Duolingo: 125)
